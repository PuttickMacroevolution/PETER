## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files(pattern="../precooked.output/tips_")
n.cores <- 1
all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
	load(input.file ,verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}
getwd()
ltt.write <- gsub(".R", ".dvltt", input.file)#
	assign(ltt.write, ltt.out)#
	save(list=ltt.write, file=paste0("../outputs/", gsub(".R", ".dvltt.R", input.file)), compress="xz")
## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files(pattern="../precooked.output/tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(input.file ,verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}#
	ltt.write <- gsub(".R", ".dvltt", input.file)#
	assign(ltt.write, ltt.out)#
	save(list=ltt.write, file=paste0("../outputs/", gsub(".R", ".dvltt.R", input.file)), compress="xz")
ltt.out
input.file
input.file <- list.files("../precooked.output/", pattern="tips_")
input.file
## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files("../precooked.output/", pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(input.file ,verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}#
	ltt.write <- gsub(".R", ".dvltt", input.file)#
	assign(ltt.write, ltt.out)#
	save(list=ltt.write, file=paste0("../outputs/", gsub(".R", ".dvltt.R", input.file)), compress="xz")
rm(list=ls(all=TRUE))
## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files("../precooked.output/", pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(input.file ,verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files("../precooked.output/", pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1
load(input.file ,verbose=TRUE)
paste0("../precooked.output/", input.file)
load(paste0("../precooked.output/", input.file), verbose=TRUE)
rm(list=ls(all=T))
## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files(pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(paste0("../precooked.output/", input.file), verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}#
	ltt.write <- gsub(".R", ".dvltt", input.file)#
	assign(ltt.write, ltt.out)#
	save(list=ltt.write, file=paste0("../outputs/", gsub(".R", ".dvltt.R", input.file)), compress="xz")
rm(list=ls(all=T))
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files(pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(paste0("../precooked.output/", input.file), verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}
ltt.write <- gsub(".R", ".dvltt", input.file)
assign(ltt.write, ltt.out)
ltt.out
load(paste0("../precooked.output/", input.file), verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}
rm(list=ls(all=T))
## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files(pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(paste0("../precooked.output/", input.file), verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()
getwd()
load(paste0("../precooked.output/", input.file), verbose=TRUE)
## Puttick et al. #
## Take simulated data and pruned trees of all fossils, then estimate parameters Phylogenetic Comparative models:#
## Brownian motion, Ornstein-Uhlenbeck, and Early Burst using the motmot package#
#
library(motmot)#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## input file for parallel processing on Mac and Linux machines#
	setwd("../precooked.output/")#
	all.files <- "tips_50.mu_0.4.severity_0.5.random_0.01.R"#
#
# run over all iterations and output PCM model parameters and log-likelihood values#
	for(count in 1:length(all.files)) {#
		load(all.files[count] ,verbose=T)#
		in.file <- eval(parse(text=gsub(".R", "", all.files[count])))#
		bm.aicc <- eb.aicc <- ou.aicc <- c()#
		for(phy.x in 1:100) {	#
			phy <- in.file[[phy.x]][[1]]#
			extant.phy <- drop.fossil(phy)#
			drop.tips <- which(is.na(match(phy$tip.label, extant.phy$tip.label)))#
			phy.tip <- which(phy$edge[,2] <= Ntip(phy))#
			y.all <- in.file[[phy.x]]$trait.matrix[[1]][phy.tip , 2]#
			if(length(drop.tips) > 0) {#
				phy.y <- as.matrix(y.all[-drop.tips])#
			} else {#
				phy.y <- as.matrix(y.all)#
			}#
		rownames(phy.y) <- extant.phy$tip.label#
		bm.aicc <- rbind(bm.aicc, unlist(transformPhylo.ML(y=phy.y, phy=extant.phy, model="bm")))#
		eb.aicc <- rbind(eb.aicc, unlist(suppressWarnings(transformPhylo.ML(y=phy.y, phy=extant.phy, model="ACDC", upperBound=-1e-6, modelCI=FALSE))))#
		ou.aicc <- rbind(ou.aicc, suppressWarnings(transformPhylo.ML(y=phy.y, phy=extant.phy, model="OU",modelCI=FALSE)))#
		cat("\r", paste0(phy.x, " %"))#
	}#
	out.all <- list(bm.aicc, eb.aicc, ou.aicc)#
	name.out <- gsub(".R", ".models", all.files[count])#
	assign(name.out, out.all)#
	save(list=name.out, file=paste0("../disparity.analysis/outputs/", gsub(".R", ".models.R", all.files[count])))#
}
