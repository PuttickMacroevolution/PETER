## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files(pattern="../precooked.output/tips_")
n.cores <- 1
all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
	load(input.file ,verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}
getwd()
ltt.write <- gsub(".R", ".dvltt", input.file)#
	assign(ltt.write, ltt.out)#
	save(list=ltt.write, file=paste0("../outputs/", gsub(".R", ".dvltt.R", input.file)), compress="xz")
## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files(pattern="../precooked.output/tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(input.file ,verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}#
	ltt.write <- gsub(".R", ".dvltt", input.file)#
	assign(ltt.write, ltt.out)#
	save(list=ltt.write, file=paste0("../outputs/", gsub(".R", ".dvltt.R", input.file)), compress="xz")
ltt.out
input.file
input.file <- list.files("../precooked.output/", pattern="tips_")
input.file
## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files("../precooked.output/", pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(input.file ,verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}#
	ltt.write <- gsub(".R", ".dvltt", input.file)#
	assign(ltt.write, ltt.out)#
	save(list=ltt.write, file=paste0("../outputs/", gsub(".R", ".dvltt.R", input.file)), compress="xz")
rm(list=ls(all=TRUE))
## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files("../precooked.output/", pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(input.file ,verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files("../precooked.output/", pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1
load(input.file ,verbose=TRUE)
paste0("../precooked.output/", input.file)
load(paste0("../precooked.output/", input.file), verbose=TRUE)
rm(list=ls(all=T))
## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files(pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(paste0("../precooked.output/", input.file), verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}#
	ltt.write <- gsub(".R", ".dvltt", input.file)#
	assign(ltt.write, ltt.out)#
	save(list=ltt.write, file=paste0("../outputs/", gsub(".R", ".dvltt.R", input.file)), compress="xz")
rm(list=ls(all=T))
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files(pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(paste0("../precooked.output/", input.file), verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}
ltt.write <- gsub(".R", ".dvltt", input.file)
assign(ltt.write, ltt.out)
ltt.out
load(paste0("../precooked.output/", input.file), verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()#
#
	for(xx in 1:100) {#
		ltt.out.temp <- in.file[[xx]]$ltt#
		going <- c()		#
		root.state <- in.file[[xx]]$root.state#
		x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
			x.in <- as.matrix(x)#
			n.col <- ncol(x.in)#
			if(nrow(x.in) > 2) {#
				euclid.out <- unlist(dispRity(x.in, metric = c(median, pairwise.dist), method="euclidean")$disparity)	#
				if(n.col == 1) x.in <- cbind(as.matrix(x), 0)#
				sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
				sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
				if(n.col == 1) x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
				centroid.out <- unlist(dispRity(x.in, metric = c(centroids, median), centroid=root.state)$disparity)#
				cbind(euclid.out, sov.out, sor.out, centroid.out)#
				} else {#
				cbind(rep(NA, 4))#
				}#
			}#
		)#
		x.out <- t(x.out)#
		node.info <- cbind(ltt.out.temp, x.out)#
		colnames(node.info)[-c(1:2)] <- c("median.euclidean", "sov", "sor", "centroid")#
		ltt.out[[xx]] <- node.info#
	}
rm(list=ls(all=T))
## Puttick et al. #
## Estimate disparity for generated data using median pairwise euclidean distance, median pairwise distance from the root,#
## Sum Of Variances, and Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(RSOLE)#
library(dispRity)#
#
## files to summarise#
input.file <- list.files(pattern="tips_")#
#
## n cores for parallel processing on Mac and Linux machines#
	n.cores <- 1#
#
## for multiple files uncomment the below#
# all.outs <- mclapply(1:length(sigma.files), mc.cores=n.cores, FUN=function(count) {#
#
	load(paste0("../precooked.output/", input.file), verbose=TRUE)#
	in.file <- eval(parse(text=gsub(".R", "", input.file)))#
	ltt.out <- list()
getwd()
load(paste0("../precooked.output/", input.file), verbose=TRUE)
## XXX et al.#
## Estimate disparity for generated data using median pairwise euclidean#
## distance, median pairwise distance from the root, Sum Of Variances, and#
## Sum Of Ranges using the dispRity package.#
#
library(parallel)#
library(PETER)#
library(dispRity)#
#
## files to summarise#
setwd("../precooked.output/")#
input.file <- list.files(pattern = "tips_")#
#
## n cores for parallel processing on Mac and Linux machines.#
	n.cores <- 1#
#
## For multiple files uncomment the lines below.#
# all.outs <- mclapply(1:length(sigma.files),#
#   mc.cores = n.cores, FUN = function(count) {#
#
# Single file example.#
load(input.file, verbose = TRUE)#
in.file <- eval(parse(text = gsub(".R", "", input.file)))#
ltt.out <- list()#
#
for (xx in 1:100) {#
  ltt.out.temp <- in.file[[xx]]$ltt#
	going <- c()#
	root.state <- in.file[[xx]]$root.state#
	x.out <- sapply(in.file[[xx]]$node.traits, function(x) {#
	  x.in <- as.matrix(x)#
		n.col <- ncol(x.in)#
		if (nrow(x.in) > 2) {#
		  euclid.out <- unlist(dispRity(x.in,#
			  metric = c(median, pairwise.dist), method = "euclidean")$disparity)#
			if (n.col == 1)#
			  x.in <- cbind(as.matrix(x), 0)#
			sov.out <- unlist(dispRity(x.in, metric = c(sum, variances))$disparity)#
			sor.out <- unlist(dispRity(x.in, metric = c(sum, ranges))$disparity)#
			if (n.col == 1)#
			  x.in <- cbind(as.matrix(x), in.file[[xx]]$root.state)#
			centroid.out <- unlist(dispRity(x.in,#
			  metric = c(centroids, median), centroid = root.state)$disparity)#
			cbind(euclid.out, sov.out, sor.out, centroid.out)#
		} else {#
		  cbind(rep(NA, 4))#
		}#
	})#
	x.out <- t(x.out)#
	node.info <- cbind(ltt.out.temp, x.out)#
	colnames(node.info)[-c(1:2)] <-#
	  c("median.euclidean", "sov", "sor", "centroid")#
	ltt.out[[xx]] <- node.info#
}#
#
ltt.write <- gsub(".R", ".dvltt", input.file)#
assign(ltt.write, ltt.out)#
save(list = ltt.write, file =#
  paste0("../disparity.analysis/outputs/", gsub(".R", ".dvltt.R", input.file)),#
	compress = "xz")
